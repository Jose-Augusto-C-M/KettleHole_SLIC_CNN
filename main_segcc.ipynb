{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_segcc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1Xv8uGWDLY5rj2cR4anH996SvkkgWm2FH",
      "authorship_tag": "ABX9TyPU4k2q9maa1oeDcaExKJmw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jose-Augusto-C-M/KettleHole_SLIC_CNN/blob/main/main_segcc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwgjfxaD3_hL",
        "outputId": "47146e09-c546-4d7b-ad05-1eb1fb3ded35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtqdm() Progress Bar Models:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load Model H5:Xception_transfer_learning_adagrad.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "tqdm() Progress Bar Files: 0it [00:00, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/datasets/dataset_anette/data_labelme/image/100_0002_0033.JPG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:79: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tensorflow.keras import applications \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Model, load_model\n",
        "from numpy import resize, expand_dims\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras import backend as K\n",
        "import glob\n",
        "from skimage import segmentation\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.util import img_as_float, img_as_ubyte\n",
        "import tensorflow as tf\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from skimage.util import img_as_float, img_as_ubyte\n",
        "from PIL import Image\n",
        "from numpy import resize, expand_dims\n",
        "from IPython.display import HTML, display\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import pylab\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "import functools\n",
        "import multiprocessing\n",
        "from multiprocessing import Process, Manager\n",
        "import threading\n",
        "import tensorflow as tf\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "def synchronized(wrapped):\n",
        "    lock = threading.Lock()\n",
        "    @functools.wraps(wrapped)\n",
        "    def _wrap(*args, **kwargs):\n",
        "        with lock:\n",
        "            return wrapped(*args, **kwargs)\n",
        "    return _wrap\n",
        "class Classfield_segmented(object):\n",
        "       c = csv.writer(open(\"dados.csv\", \"w\", newline=''))\n",
        "       location_drive='/content/drive/MyDrive/datasets/dataset_anette/data_labelme/' #caminho até onde está a base das pastas\n",
        "       IMG_WIDTH, IMG_HEIGHT = 224,224\n",
        "       dict_classes=['background','Cirsium_arvense','Salix spec','Oenanthe aquatica','Phalaris arundinacea','Urtica dioica','Arctium spec.','Carex riparia live','Salix cinerea','Typha live','Urtica_dioica', 'Phragmites australis live','Phragmites australis mix live and dead','Nymphaeidae','water']\n",
        "\n",
        "#'01':'background', '02':'Cirsium arvense', '03':'Salix spec', '04':'Oenanthe aquatica', '05': 'Phalaris arundinacea', '06': 'Urtica dioica', '07': 'Arctium spec.', '08': 'Carex riparia live','09': 'Salix cinerea','10': 'Typha live','11': 'Phragmites australis live','12': 'Phragmites australis mix live and dead','13':'Nymphaeidae','14': 'water'\n",
        "\n",
        "       color_classes=[(0, 0, 0),(255, 255, 255),(0, 0, 255),(255, 0, 0),(0, 255, 0),(255, 255, 0),(255, 0, 255),(0, 255, 255),(255, 153, 153),(153, 153, 204),(102, 0, 0),(100,100,0),(100,150,50),(100,150,150),(20,20,180)]\n",
        "       model=None  \n",
        "       \n",
        "       def getRAMinfo(self):\n",
        "         p = os.popen('free')\n",
        "         i = 0\n",
        "         while 1:\n",
        "            i = i + 1\n",
        "            line = p.readline()\n",
        "            if i==2:\n",
        "              return(line.split()[1:4])\n",
        "              \n",
        "       @synchronized\n",
        "       \n",
        "       def predict(self,image):\n",
        "          predict=self.model.predict(image)\n",
        "          return np.argmax(predict, axis=1)\n",
        "          \n",
        "       def job_process(self,model_name,filename, preprocess_input, decode_predictions,list_iou):\n",
        "            print(filename)\n",
        "            im=io.imread(filename)\n",
        "            #plt.imshow(im)\n",
        "            \n",
        "            #plt.show()\n",
        "            \n",
        "            img_load=im.copy()\n",
        "            ##create a superpixels\n",
        "            segments = segmentation.slic(img_load, n_segments=4000,compactness=10, sigma=5)\n",
        "            #mark boundaries\n",
        "            img_slic=mark_boundaries(img_load, segments)\n",
        "            \n",
        "            mpimg.imsave(self.location_drive + \"result/\"+model_name+\"/slic/\"+filename.split(\"image/\")[1],img_slic) #local do drive\n",
        "            #Classificando os superpixels\n",
        "            #print(segments)\n",
        "            #superpixels=[]\n",
        "            pred_list=[]\n",
        "            qtd=len(np.unique(segments))\n",
        "            print(\"Processando os superpixels da imagem\")\n",
        "            img_paint=im.copy()    \n",
        "            for (i, seg) in tqdm(enumerate( np.unique(segments )), desc = 'tqdm() Progress Bar Segments'):\n",
        "              # Create a mask, painting black all pixels outside of segment and white the pixels inside.\n",
        "              mask_segment = np.zeros(  img_load.copy().shape[:2], dtype=\"uint8\")\n",
        "              mask_segment[segments == seg] = 255\n",
        "\n",
        "              size_segment = mask_segment[segments == seg].size\n",
        "              segment =  img_load.copy() \n",
        "              segment = cv2.bitwise_and(segment, segment, mask=mask_segment)\n",
        "              # Get the countours around the segment\n",
        "              contours, _  = cv2.findContours(mask_segment,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
        "         \n",
        "              m = -1\n",
        "              max_contour = None\n",
        "              for cnt in contours:\n",
        "                       if (len(cnt) > m):\n",
        "                          m = len(cnt)\n",
        "                          max_contour = cnt\n",
        "\n",
        "              # Get the rectangle that encompasses the countour\n",
        "              x,y,w,h = cv2.boundingRect(max_contour)\n",
        "              segment = segment[y:y+h, x:x+w]\n",
        "\n",
        "              #superpixels.append(segment)\n",
        "         \n",
        "              # pre-process the image for classification\n",
        "              image = cv2.resize(segment, (self.IMG_HEIGHT, self.IMG_WIDTH))\n",
        "              image = image.astype(\"float\") / 255.0\n",
        "              image = img_to_array(image)\n",
        "              image = np.expand_dims(image, axis=0)\n",
        "           \n",
        "              predict = self.predict(image)\n",
        "              \n",
        "              color=None\n",
        "\n",
        "                 \n",
        "              for cont, name_classs in enumerate(self.dict_classes):  \n",
        "                if(self.dict_classes[predict[0]]==name_classs):\n",
        "                    color=self.color_classes[cont]\n",
        "                    break\n",
        "              #predict = np.argmax(predict, axis=1)\n",
        "              #print(predict)\n",
        "              pred_list.append(self.dict_classes[predict[0]])\n",
        "              #if(idx_segment<4):\n",
        "                #plt.imshow(segment)\n",
        "                #print(dict_classes[predict[0]])\n",
        "                #plt.show()\n",
        "                #break\n",
        "              \n",
        "              #painting  \n",
        "              height, width, channels = img_paint.shape   \n",
        "               \n",
        "              mask_inv = cv2.bitwise_not(mask_segment)\n",
        "               \n",
        "              # Paint all pixels in original image with choosed color\n",
        "              class_color = np.zeros((height,width,3), np.uint8)\n",
        "              class_color[:, :] = color\n",
        "              colored_image = cv2.addWeighted(img_paint, 0.0, class_color, 1.0, 0)\n",
        "               \n",
        "              colored_image = cv2.bitwise_and(colored_image, colored_image, mask=mask_segment)\n",
        "              clear = False\n",
        "              # Create a new image keeping the painting only in pixels inside of segments\n",
        "              new_image =   img_paint\n",
        "              new_image = cv2.bitwise_and(new_image, new_image, mask=mask_inv)\n",
        "              mask_segment[:] = 255\n",
        "              img_paint = cv2.bitwise_or(new_image, colored_image, mask=mask_segment)\n",
        "               \n",
        "             \n",
        "\n",
        "            \n",
        "            mpimg.imsave(self.location_drive + \"result/\"+model_name+\"/paint/\"+filename.split(\"image/\")[1],img_paint)\n",
        "            ##Calcula o IoU\n",
        "            \n",
        "            \"\"\"\n",
        "            im_mask=cv2.imread(self.location_drive+\"sheep_mask/\"+filename.split(\"sheep/\")[1].split(\"_img\")[0]+\"_label.png\")\n",
        "            print(self.location_drive+\"sheep_mask/\"+filename.split(\"sheep/\")[1].split(\"_img\")[0]+\"_label.png\")\n",
        "            #print(im_mask)\n",
        "            im_mask = cv2.cvtColor(im_mask, cv2.COLOR_BGR2GRAY)\n",
        "            ret,im_mask = cv2.threshold(im_mask,25, 255, cv2.THRESH_BINARY)\n",
        "            #im=cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
        "            #plt.imshow(im_mask ,cmap=pylab.gray())\n",
        "            ##target, predition\n",
        "            img_p=cv2.cvtColor(img_paint, cv2.COLOR_BGR2GRAY)\n",
        "            r,img_p = cv2.threshold(img_p, 25, 255, cv2.THRESH_BINARY)\n",
        "            intersection = np.logical_and(np.array(im_mask), np.array(img_p))\n",
        "            union = np.logical_or(im_mask,img_p)\n",
        "            \n",
        "            mpimg.imsave(\"result/\"+model_name+\"/inter/\"+filename.split(\"sheep/\")[1],intersection)\n",
        "            \n",
        "            mpimg.imsave(\"result/\"+model_name+\"/union/\"+filename.split(\"sheep/\")[1],union)\n",
        "            iou_score = np.sum(intersection) / np.sum(union)\n",
        "            print(iou_score)\n",
        "            list_iou.append(iou_score)\n",
        "            \n",
        "            self.c.writerow([str(model_name),str(filename.split(\"sheep/\")[1]),str(iou_score)])             \n",
        "            \"\"\"\n",
        "     \n",
        "       def process(self):       \n",
        "              dict_preprocessing = {}\n",
        "              dict_preprocessing[1] = applications.vgg16.preprocess_input, applications.vgg16.decode_predictions\n",
        "              dict_preprocessing[2] = applications.inception_v3.preprocess_input, applications.inception_v3.decode_predictions\n",
        "              dict_preprocessing[3] = applications.densenet.preprocess_input, applications.densenet.decode_predictions\n",
        "              dict_preprocessing[4] = applications.resnet_v2.preprocess_input, applications.resnet_v2.decode_predictions\n",
        "              dict_preprocessing[5] = applications.xception.preprocess_input, applications.xception.decode_predictions\n",
        "\n",
        "              self.c.writerow([\"Modelo\",\"Arquivo\",\"IOU\"])\n",
        "              #names of models\n",
        "              list_model=[\"Xception\"] #,\"ResNet152V2\", \"InceptionV3\",\"VGG16\", \"DenseNet201\"]\n",
        "              for model_name in tqdm(list_model, desc = 'tqdm() Progress Bar Models'):\n",
        "                K.clear_session()\n",
        "                self.model = load_model(self.location_drive+\"model/\"+model_name+\"_transfer_learning_adagrad.h5\")\n",
        "                preprocess_input=None\n",
        "                decode_predictions=None\n",
        "                if model_name==\"VGG16\":\n",
        "                   preprocess_input, decode_predictions = dict_preprocessing[1]\n",
        "                if model_name==\"InceptionV3\":\n",
        "                   preprocess_input, decode_predictions = dict_preprocessing[2]\n",
        "                if model_name==\"DenseNet201\":\n",
        "                   preprocess_input, decode_predictions = dict_preprocessing[3]\n",
        "                if model_name==\"ResNet152V2\":\n",
        "                   preprocess_input, decode_predictions = dict_preprocessing[4]\n",
        "                if model_name==\"Xception\":\n",
        "                   preprocess_input, decode_predictions = dict_preprocessing[5]   \n",
        "                list_iou=[]\n",
        "                print(\"Load Model H5:\"+model_name+\"_transfer_learning_adagrad.h5\")\n",
        "                #Process each image\n",
        "                threads=[]\n",
        "                for filename in tqdm(glob.iglob(self.location_drive+'image/*.JPG', recursive=True), desc = 'tqdm() Progress Bar Files'):\n",
        "                   self.job_process(model_name,filename,preprocess_input, decode_predictions,list_iou)\n",
        "                   #th = threading.Thread(target=self.job_process,args=(model_name,filename,preprocess_input, decode_predictions,list_iou ))\n",
        "                   #threads.append(th)\n",
        "                \n",
        "                # Output is in kb, here I convert it in Mb for readability\n",
        "                RAM_stats = self.getRAMinfo()\n",
        "                RAM_total = round(int(RAM_stats[0]) / 1000,1)\n",
        "                RAM_used = round(int(RAM_stats[1]) / 1000,1)\n",
        "                print(\"RAM Total : \"+str(RAM_total))\n",
        "                print(\"RAM Used : \"+str(RAM_used))\n",
        "                 \n",
        "                print(\"Wait a moment, the threads are processing \"+str(len(threads)) +\" images, it may be delayed depending on the size or quantity of the images!\")\n",
        "                with tqdm(total=len(threads)) as pbar:\n",
        "                  for  t in threads:\n",
        "                        t.start()\n",
        "                        #t.join()\n",
        "                        if((RAM_total)<33000):#se menor que 10gb\n",
        "                             RAM_stats = self.getRAMinfo()\n",
        "                             RAM_used = round(int(RAM_stats[1]) / 1000,1)\n",
        "                             if((RAM_total-RAM_used)<6000):\n",
        "                               t.join()\n",
        "                             pbar.update(1)\n",
        "                  pbar.close()\n",
        "                for  t in threads:\n",
        "                   t.join()\n",
        "                #print(\"Average IoU\"+ str(np.mean(list_iou)))\n",
        "                #print(\"Model_name:\"+list_iou)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_file= Classfield_segmented()\n",
        "    process_file.process()\n"
      ]
    }
  ]
}